{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM para predecir el índice Dow Jones incluyendo como entrada el sentimiento expresado por Donal Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial = pd.read_csv(\"./Trump_SA_For_LSTM.csv\",header=0,delimiter=',', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cambio el formato de la fecha para adaptarla al formato utilizado por el dataset del Dow Jones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial['Date'] = pd.to_datetime(df_Trump_Initial['fecha'], errors='coerce')\n",
    "#df_Trump_Initial['fecha']\n",
    "df_Trump_Initial['Date']=df_Trump_Initial['Date'].dt.strftime('%Y-%m-%d')\n",
    "df_Trump_Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.drop(['fecha'], axis='columns', inplace=True)\n",
    "df_Trump_Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.to_csv('Trump_SA_For_LSTM_date_Modified.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.index.name='index'\n",
    "df_Trump_Initial=df_Trump_Initial.drop(df_Trump_Initial.columns[[0]], axis='columns')\n",
    "\n",
    "df_Trump_Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dropout\n",
    "import pandas as pd\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "import datetime\n",
    "from matplotlib import style\n",
    "\n",
    "# ignore warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports:\n",
    "A continuación importo las siguintes librerías: \n",
    "* Keras para crear la red neuronal\n",
    "* pandas y pandas_data reader para obtener y analizar el stock\n",
    "* datetime para fijar las fechas de stock para el análisis de datos\n",
    "* numpy para redimensionar los datos a alimentar en la red neuronal\n",
    "* matplotlib para trazar y visualizar los datos\n",
    "* advertencias para ignorar cualquiera de las advertencias no deseadas que aparecen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengo los datos de stock a través del API de yahoo:\n",
    "style.use('ggplot')\n",
    "\n",
    "# Extraigo los datos desde el  2014 al 2019 para entrenar el modelo\n",
    "inicio = datetime.datetime(2014,12,31)\n",
    "fin = datetime.datetime(2019,12,31)\n",
    "train_df = web.DataReader(\"^DJI\", 'yahoo', inicio, fin) \n",
    "\n",
    "# Extraigo los datos del 2020 para testear el modelo \n",
    "start = datetime.datetime(2020,1,1)\n",
    "end = datetime.datetime(2020,7,24)\n",
    "#fin = datetime.date.today()\n",
    "test_df = web.DataReader(\"^DJI\", 'yahoo', start, end) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "test_df['High'].plot(legend=True)\n",
    "train_df['High'].plot(legend=True)\n",
    "\n",
    "plt.legend(['Entrenamiento (2014-2019)', 'Validación (2020)'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obteniendo los datos de las acciones: \n",
    "* Este código cambia nuestro estilo de trazado a ggplot.   En el siguiente link existe más información sobre ggplot [aqui](https://matplotlib.org/3.1.1/gallery/style_sheets/ggplot.html). \n",
    "* Utilizo pandas_datareader como \"web\" para obtener los datos de los precios de las acciones utilizando la función DataReader que obtiene los datos financieros y los almacena en un dataframe.\n",
    "* Obtengo los datos del índice DowJones desde el 2014 hasta el 2019 para el entrenamiento del modelo.\n",
    "* Obtengo los datos del índice DowJones desde el año 2020 hasta la actualidad para testearlo.\n",
    "* \"^DJI\" es el símbolo de cotización de las acciones para el índice Dow Jones y especifico 'yahoo' para obtener los datos utilizando la API de finanzas de Yahoo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordeno por fecha\n",
    "train_df = train_df.sort_values('Date')\n",
    "test_df = test_df.sort_values('Date')\n",
    "\n",
    "# corrigo la fecha \n",
    "train_df.reset_index(inplace=True)\n",
    "train_df.set_index(\"Date\", inplace=True)\n",
    "test_df.reset_index(inplace=True)\n",
    "test_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuevas features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevas features para entrenar el modelo aplicadas a los datos de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aux=train_df.copy()\n",
    "Aux['h_o'] = (Aux['High'] - Aux['Close'])/Aux['Close'] *100 #porcentaje máximo de ganancia en el día respecto al cierre\n",
    "Aux['pct_chng'] = (Aux['Close'] - Aux['Open'])/Aux['Open'] *100 #porcentaje de variación diaria \n",
    "train_df = Aux[['High','Low','Open','Volume','Adj Close','h_o','pct_chng']]\n",
    "#df = A[['Close','pct_chng']]\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Commodity Channel Index (CCI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Índice de canal de productos básicos (CCI)\n",
    "El índice de canal de productos básicos (CCI) es un oscilador que fue presentado originalmente por Donald Lambert en 1980. El CCI se puede utilizar para identificar giros cíclicos entre las clases de activos, ya sean materias primas, índices, acciones o ETF. Los operadores también utilizan CCI para identificar los niveles de sobrecompra / sobreventa de valores.\n",
    "\n",
    "Estimacion\n",
    "El CCI analiza la relación entre el precio y un promedio móvil. Los pasos involucrados en la estimación de CCI incluyen:\n",
    "\n",
    "Calculando el precio típico de seguridad. El precio típico se obtiene promediando el precio máximo, mínimo y de cierre del día.\n",
    "Encontrar el promedio móvil para el número de días elegido en función del precio típico.\n",
    "Calcular la desviación estándar para el mismo período que el utilizado para el MA.\n",
    "La fórmula para CCI viene dada por:\n",
    "\n",
    "\n",
    "CCI = (Precio típico - MA del precio típico) / (0.015 * Desviación estándar del precio típico)\n",
    "\n",
    "\n",
    "El índice se escala por un factor inverso de 0.015 para proporcionar números más legibles.\n",
    "\n",
    "Análisis\n",
    "CCI se puede utilizar para determinar los niveles de sobrecompra y sobreventa. Las lecturas por encima de +100 pueden implicar una condición de sobrecompra, mientras que las lecturas por debajo de −100 pueden implicar una condición de sobreventa. Sin embargo, se debe tener cuidado porque la seguridad puede continuar subiendo después de que el indicador CCI se sobrecompra. Del mismo modo, los valores pueden continuar bajando después de que el indicador se sobreventa.\n",
    "\n",
    "Siempre que la seguridad se encuentre en niveles de sobrecompra / sobreventa como lo indica el CCI, existe una buena posibilidad de que el precio vea correcciones. Por lo tanto, un operador puede usar dichos niveles de sobrecompra / sobreventa para ingresar en posiciones cortas / largas.\n",
    "\n",
    "Los comerciantes también pueden buscar señales de divergencia para tomar posiciones adecuadas utilizando CCI. Una divergencia alcista ocurre cuando la seguridad subyacente hace un mínimo más bajo y el CCI forma un mínimo más alto, lo que muestra un menor impulso a la baja. Del mismo modo, se forma una divergencia bajista cuando la seguridad registra un máximo más alto y el CCI forma un máximo más bajo, lo que muestra un menor impulso al alza.\n",
    "\n",
    "Código de Python para calcular el índice del canal de productos básicos:\n",
    "\n",
    "\n",
    "En el siguiente código, se utilizan las funciones Series, rollingmean, rollingstd y join para calcular el índice del canal de productos básicos. La función Serie se usa para formar una serie que es un objeto de matriz unidimensional que contiene una matriz de datos. La función rollingmean toma una serie temporal o un marco de datos junto con el número de períodos y calcula la media. La función rollingstd calcula la desviación estándar en función del precio proporcionado. La función de unión une una serie dada con una serie / marco de datos específico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo los paquetes y módulos necesarios\n",
    "from pandas_datareader import data as pdr\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance\n",
    "import pandas as pd\n",
    "\n",
    "# Commodity Channel Index \n",
    "def CCI(data, ndays): \n",
    "    TP = (data['High'] + data['Low'] + data['Adj Close']) / 3 \n",
    "    CCI = pd.Series((TP - TP.rolling(ndays).mean()) / (0.015 * TP.rolling(ndays).std()),\n",
    "                    name = 'CCI') \n",
    "    data = data.join(CCI) \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Calculo el Commodity Channel Index(CCI) para DJ basándome en la Moving average de 36 días\n",
    "n = 36\n",
    "DJ_CCI = CCI(train_df, n)\n",
    "CCIAux = DJ_CCI['CCI']\n",
    "train_df['CCI']=DJ_CCI['CCI']\n",
    "\n",
    "# Plotting the Price Series chart and the Commodity Channel index below\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_xticklabels([])\n",
    "plt.plot(train_df['Adj Close'],lw=1)\n",
    "plt.title('DJ Price Chart')\n",
    "plt.ylabel('Close Price')\n",
    "plt.grid(True)\n",
    "bx = fig.add_subplot(2, 1, 2)\n",
    "plt.plot(CCIAux,'k',lw=0.75,linestyle='-',label='CCI')\n",
    "plt.legend(loc=2,prop={'size':9.5})\n",
    "plt.ylabel('CCI values')\n",
    "plt.grid(True)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Ease of Movement (EVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ease of Movement (EVM) es un oscilador basado en volumen que fue desarrollado por Richard Arms. EVM indica la facilidad con la que los precios suben o bajan teniendo en cuenta el volumen de la seguridad. Por ejemplo, un aumento de precio en un volumen bajo significa que los precios avanzaron con relativa facilidad, y hubo poca presión de venta. Los valores positivos de EVM implican que el mercado se está moviendo hacia arriba con facilidad, mientras que los valores negativos indican un descenso fácil.\n",
    "\n",
    "Estimación Para calcular el EMV, primero calculamos la distancia recorrida. Está dado por:\n",
    "\n",
    "Distancia movida = ((Alta actual + Baja actual) / 2 - (Alta anterior + Baja anterior) / 2)\n",
    "\n",
    "Calculo la relación de Box que usa el volumen y el rango alto-bajo:\n",
    "\n",
    "Relación de caja = (Volumen / 100,000,000) / (Alto actual - Bajo actual) EMV = Distancia movida / Relación de caja Para calcular el EMV de n períodos tomamos el promedio móvil simple de n períodos del EMV de 1 período.\n",
    "\n",
    "La facilidad de análisis de movimiento (EMV) se puede utilizar para confirmar una tendencia alcista o bajista. Una Facilidad de Movimiento positiva sostenida junto con un mercado en alza confirma una tendencia alcista, mientras que los valores de Facilidad de Movimiento negativos con precios a la baja confirman una tendencia bajista. Además de usarse como un indicador independiente, la facilidad de movimiento (EMV) también se usa con otros indicadores en el análisis de gráficos.\n",
    "\n",
    "En el siguiente código, Utilizo las funciones Series, rollingmean, shift y join para calcular el indicador de Facilidad de movimiento (EMV). La función Serie se usa para formar una serie que es un objeto de matriz unidimensional que contiene una matriz de datos. La función rollingmean toma una serie temporal o un marco de datos junto con el número de períodos y calcula la media. La función de desplazamiento se utiliza para obtener el precio máximo y mínimo del día anterior. La función de unión une una serie dada con una serie / marco de datos específico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ease Of Movement (EVM) Code\n",
    "\n",
    "\n",
    " \n",
    "# Ease of Movement \n",
    "def EVM(data, ndays): \n",
    " dm = ((data['High'] + data['Low'])/2) - ((data['High'].shift(1) + data['Low'].shift(1))/2)\n",
    " br = (data['Volume'] / 100000000) / ((data['High'] - data['Low']))\n",
    " EVM = dm / br \n",
    " EVM_MA = pd.Series(EVM.rolling(ndays).mean(), name = 'EVM') \n",
    " data = data.join(EVM_MA) \n",
    " return data \n",
    " \n",
    "\n",
    "# Calculo Ease of Movement for DJ en 36 días\n",
    "n = 36\n",
    "DJ_EVM = EVM(train_df, n)\n",
    "EVMAux = DJ_EVM['EVM']\n",
    "train_df['EVM']=DJ_EVM['EVM']\n",
    "\n",
    "\n",
    "# Plotting the Price Series chart and the Ease Of Movement below\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_xticklabels([])\n",
    "plt.plot(train_df['Adj Close'],lw=1)\n",
    "plt.title('DJ Price Chart')\n",
    "plt.ylabel('Close Price')\n",
    "plt.grid(True)\n",
    "bx = fig.add_subplot(2, 1, 2)\n",
    "plt.plot(EVMAux,'k',lw=0.75,linestyle='-',label='EVM(36)')\n",
    "plt.legend(loc=2,prop={'size':9})\n",
    "plt.ylabel('EVM values')\n",
    "plt.grid(True)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Moving Average (MA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media móvil es uno de los indicadores técnicos más utilizados. Se usa junto con otros indicadores técnicos o puede formar el bloque de construcción para el cálculo de otros indicadores técnicos.\n",
    "\n",
    "Un \"promedio móvil\" es el promedio de los precios de los activos durante el número \"x\" de días / semanas. El término \"mover\" se usa porque el grupo de datos avanza con cada nuevo día de negociación. Para cada nuevo día, incluimos el precio de ese día y excluimos el precio del primer día en la secuencia de datos.\n",
    "\n",
    "Los promedios móviles más utilizados son los promedios móviles de 5 días, 10 días, 20 días, 50 días y 200 días.\n",
    "\n",
    "Estimacion\n",
    "Existen diferentes tipos de promedios móviles utilizados para el análisis, un promedio móvil simple (SMA), un promedio móvil ponderado (WMA) y el promedio móvil exponencial (EMA).\n",
    "\n",
    "Para calcular una SMA de 20 días, tomamos la suma de los precios durante 20 días y la dividimos entre 20. Para llegar al siguiente punto de datos para la SMA de 20 días, incluimos el precio del siguiente día de negociación, excluyendo el precio. del primer día de negociación. De esta manera, el grupo de datos avanza.\n",
    "\n",
    "La SMA asigna pesos iguales a cada punto de precio en el grupo. Cuando calculamos un WMA de 20 días, asignamos pesos variables a cada punto de precio. El último precio, es decir, el precio de 20 días obtiene el mayor peso, mientras que el primer precio obtiene el menor peso. Esta suma se divide por la suma de los pesos utilizados.\n",
    "\n",
    "Para calcular la EMA de 20 días, primero calculamos el primer valor EMA utilizando una media móvil simple. Luego calculamos el multiplicador y, a partir de entonces, para calcular el segundo valor de EMA, usamos el multiplicador y el EMA del día anterior. Esta fórmula se usa para calcular los valores EMA posteriores.\n",
    "\n",
    "SMA: suma de 20 períodos / 20\n",
    "Multiplicador: (2 / (Periodos de tiempo + 1)) = (2 / (20 + 1)) = 9.52%\n",
    "EMA: {Precio de cierre - EMA (día anterior)} x multiplicador + EMA (día anterior).\n",
    "Análisis\n",
    "El promedio móvil indica si una tendencia ha comenzado, finalizado o revertido. El promedio de los precios produce una línea más suave que facilita la identificación de la tendencia subyacente. Sin embargo, la media móvil va a la zaga de la acción del mercado.\n",
    "\n",
    "Un promedio móvil más corto es más sensible que un promedio móvil más largo. Sin embargo, es propenso a generar señales comerciales falsas.\n",
    "\n",
    "Uso de una sola media móvil: se puede usar una sola media móvil para generar señales comerciales. Cuando el precio de cierre se mueve por encima del promedio móvil, se genera una señal de compra y viceversa. Cuando se utiliza un único promedio móvil, se debe seleccionar el período promedio de tal manera que sea sensible al generar señales comerciales y al mismo tiempo insensible al emitir señales falsas.\n",
    "\n",
    "Uso de dos promedios móviles: el uso de un solo promedio móvil puede ser desventajoso. Por lo tanto, muchos operadores usan dos promedios móviles para generar señales. En este caso, se genera una señal de compra cuando el promedio más corto cruza por encima del promedio más largo. Del mismo modo, se genera una venta cuando los cruces más cortos están por debajo del promedio más largo. El uso de dos promedios móviles reduce las señales falsas que son más probables cuando se usa un solo promedio móvil.\n",
    "\n",
    "Los comerciantes también usan tres promedios móviles, como el sistema de promedio móvil de 5, 10 y 20 días ampliamente utilizado en los mercados de productos básicos.\n",
    "\n",
    "\n",
    "En el siguiente código, utilizo las funciones Serie, media móvil y unión para crear las funciones SMA y EWMA. La función Serie se usa para formar una serie que es un objeto de matriz unidimensional que contiene una matriz de datos. La función rolling_mean toma una serie temporal o un marco de datos junto con el número de períodos y calcula la media. La función de unión une una serie dada con una serie / marco de datos específico.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Moving Average \n",
    "def SMA(data, ndays): \n",
    " SMA = pd.Series(train_df['Adj Close'].rolling(ndays).mean(), name = 'SMA') \n",
    " data = data.join(SMA) \n",
    " return data\n",
    "\n",
    "# Exponentially-weighted Moving Average \n",
    "def EWMA(data, ndays): \n",
    " EMA = pd.Series(data['Adj Close'].ewm(span = ndays, min_periods = ndays - 1).mean(), \n",
    "                 name = 'EWMA_' + str(ndays)) \n",
    " data = data.join(EMA) \n",
    " return data\n",
    "\n",
    "close = train_df['Adj Close']\n",
    "\n",
    "# calculo 50 días SMA para DJ\n",
    "n = 50\n",
    "SMA_DJ = SMA(train_df,n)\n",
    "SMA_DJ = SMA_DJ.dropna()\n",
    "SMAAux = SMA_DJ['SMA']\n",
    "train_df['SMA']=SMA_DJ['SMA']\n",
    "\n",
    "\n",
    "# calculo 200 días SMA para DJ\n",
    "ew = 200\n",
    "EWMA_DJ = EWMA(train_df,ew)\n",
    "EWMA_DJ = EWMA_DJ.dropna()\n",
    "EWMAAux = EWMA_DJ['EWMA_200']\n",
    "train_df['EWMA']=EWMAAux\n",
    "\n",
    "\n",
    "\n",
    "# Plotting the NIFTY Price Series chart and Moving Averages below\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(train_df['Adj Close'],lw=1, label='DJ Prices')\n",
    "plt.plot(SMAAux,'g',lw=1, label='50-day SMA (green)')\n",
    "plt.plot(EWMAAux,'r', lw=1, label='200-day EWMA (red)')\n",
    "plt.legend(loc=2,prop={'size':11})\n",
    "plt.grid(True)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Rate of Change (ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tasa de cambio (ROC) es un indicador técnico que mide el cambio porcentual entre el precio más reciente y el precio \"n\" del día anterior. El indicador fluctúa alrededor de la línea cero.\n",
    "\n",
    "Si el ROC está aumentando, da una señal alcista, mientras que un ROC descendente da una señal bajista. Se puede calcular ROC en función de diferentes períodos para medir el impulso a corto plazo o el impulso a largo plazo.\n",
    "\n",
    "Estimacion\n",
    "\n",
    "\n",
    "ROC = [(precio de cierre hoy - precio de cierre \"n\" hace un día) / precio de cierre \"n\" hace un día))]\n",
    "\n",
    "\n",
    "Código de Python para calcular la tasa de cambio (ROC)\n",
    "\n",
    "\n",
    "En el siguiente código, utilizamos las funciones Series, diff, shift y join para calcular la Velocidad de cambio (ROC). La función Serie se usa para formar una serie que es un objeto de matriz unidimensional que contiene una matriz de datos. La función diff calcula la diferencia de precios entre el precio del día actual y el precio \"n\" del día anterior. La función de desplazamiento se utiliza para obtener el precio del día \"n\" anterior. La función de unión une una serie dada con una serie / marco de datos específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rate of Change (ROC)\n",
    "def ROC(data,n):\n",
    " N = data['Adj Close'].diff(n)\n",
    " D = data['Adj Close'].shift(n)\n",
    " ROC = pd.Series(N/D,name='Rate of Change')\n",
    " data = data.join(ROC)\n",
    " return data \n",
    " \n",
    "\n",
    "\n",
    "# Selecciono un periodo de 36\n",
    "n = 36\n",
    "DJ_ROC = ROC(train_df,n)\n",
    "ROCAux = DJ_ROC['Rate of Change']\n",
    "train_df['ROC']=DJ_ROC['Rate of Change']\n",
    "\n",
    "# Plotting the Price Series chart and the Ease Of Movement below\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(2, 1, 1)\n",
    "ax.set_xticklabels([])\n",
    "plt.plot(train_df['Adj Close'],lw=1)\n",
    "plt.title('DJ Price Chart')\n",
    "plt.ylabel('Close Price')\n",
    "plt.grid(True)\n",
    "bx = fig.add_subplot(2, 1, 2)\n",
    "plt.plot(ROCAux,'k',lw=0.75,linestyle='-',label='ROC')\n",
    "plt.legend(loc=2,prop={'size':9})\n",
    "plt.ylabel('ROC values')\n",
    "plt.grid(True)\n",
    "plt.setp(plt.gca().get_xticklabels(), rotation=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Bollinger Bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El concepto de las bandas de Bollinger fue desarrollado por John Bollinger. Estas bandas se componen de una banda superior de Bollinger y una banda inferior de Bollinger y se colocan dos desviaciones estándar por encima y por debajo de un promedio móvil.\n",
    "\n",
    "Las bandas de Bollinger se expanden y contraen en función de la volatilidad. Durante un período de creciente volatilidad, las bandas se amplían y se contraen a medida que disminuye la volatilidad. Los precios se consideran relativamente altos cuando se mueven por encima de la banda superior y relativamente bajos cuando descienden por debajo de la banda inferior.\n",
    "\n",
    "Estimacion\n",
    "Para crear las bandas, primero calculamos la SMA y luego la usamos para calcular los valores de las bandas.\n",
    "\n",
    "Banda media = promedio móvil simple de 20 días (SMA)\n",
    "Banda superior = SMA + de 20 días (2 x desviación estándar de precio de 20 días)\n",
    "Banda inferior = SMA de 20 días - (2 x desviación estándar de precio de 20 días)\n",
    "Análisis\n",
    "Para utilizar las bandas de Bollinger para generar señales, un enfoque simple sería utilizar las bandas superior e inferior como objetivos de precio. Si el precio rebota en la banda inferior y cruza la línea de promedio móvil, la banda superior se convierte en el precio objetivo superior.\n",
    "\n",
    "En el caso de un cruce del precio por debajo de la línea de promedio móvil, la banda inferior se convierte en el precio objetivo a la baja.\n",
    "\n",
    "\n",
    "En el siguiente código, ejecuto la función para crear la función de banda de Bollinger. La media y los métodos de desviación estándar se utilizan para calcular estas métricas respectivas utilizando el precio de cierre. Una vez que hemos calculado la media y la desviación estándar, calculamos la banda superior de Bollinger y la banda inferior de Bollinger. La función de banda de Bollinger se llama en los datos de precios del DJ utilizando la ventana de promedio móvil de 36 días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Bollinger Bands \n",
    "def BBANDS(data, window=n):\n",
    "    MA = data['Adj Close'].rolling(window=n).mean()\n",
    "    SD =data['Adj Close'].rolling(window=n).std()\n",
    "    data['UpperBB'] = MA + (2 * SD) \n",
    "    data['LowerBB'] = MA - (2 * SD)\n",
    "    return data\n",
    " \n",
    "\n",
    "\n",
    "# Calculo Bollinger Bands para DJ utilizando Moving average de 36 días\n",
    "n = 36\n",
    "DJ_BBANDS = BBANDS(train_df, n)\n",
    "train_df['UpperBB']=DJ_BBANDS['UpperBB']\n",
    "train_df['LowerBB']=DJ_BBANDS['LowerBB']\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "pd.concat([DJ_BBANDS['Adj Close'],DJ_BBANDS.UpperBB,DJ_BBANDS.LowerBB],axis=1).plot(figsize=(9,5),grid=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Force Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El índice de fuerza fue creado por Alexander Elder. El índice de fuerza tiene en cuenta la dirección del precio de las acciones, la extensión del movimiento del precio de las acciones y el volumen. Usando estos tres elementos, forma un oscilador que mide la presión de compra y venta.\n",
    "\n",
    "Cada uno de estos tres factores juega un papel importante en la determinación del índice de fuerza. Por ejemplo, un gran avance en los precios, dado por el alcance del movimiento de los precios, muestra una fuerte presión de compra. Una gran disminución en el volumen pesado indica una fuerte presión de venta.\n",
    "\n",
    "Estimacion\n",
    "Ejemplo: cálculo del índice de fuerza (1) y el índice de fuerza (15).\n",
    "\n",
    "El índice de fuerza (1) = {Cerrar (período actual) - Cerrar (período anterior)} x Volumen del período actual\n",
    "\n",
    "\n",
    "El índice de fuerza para el período de 15 días es un promedio móvil exponencial del índice de fuerza de 1 período.\n",
    "\n",
    "Análisis\n",
    "El índice de fuerza se puede usar para determinar o confirmar la tendencia, identificar correcciones y presagiar reversiones con divergencias. Se usa un índice de fuerza más corto para determinar la tendencia a corto plazo, mientras que un índice de fuerza más largo, por ejemplo, un índice de fuerza de 100 días se puede usar para determinar la tendencia a largo plazo en los precios.\n",
    "\n",
    "Un índice de fuerza también se puede utilizar para identificar correcciones en una tendencia dada. Para hacerlo, se puede usar junto con un indicador de seguimiento de tendencia. Por ejemplo, uno puede usar un EMA de 22 días para la tendencia y un índice de fuerza de 2 días para identificar correcciones en la tendencia.\n",
    "\n",
    "\n",
    "En el siguiente código, utilizamos las funciones Series, diff y join para calcular el índice de fuerza. La función Serie se usa para formar una serie que es un objeto de matriz unidimensional que contiene una matriz de datos. La función diff calcula la diferencia entre el punto de datos actual y el punto de datos \"n\" con períodos / días de diferencia. La función de unión une una serie dada con una serie / marco de datos específico.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force Index \n",
    "def ForceIndex(data, ndays): \n",
    "    FI = pd.Series(data['Adj Close'].diff(ndays) * data['Volume'], name = 'ForceIndex') \n",
    "    data = data.join(FI) \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculo el Force Index para DJ\n",
    "n = 36\n",
    "DJ_ForceIndex = ForceIndex(train_df,n)\n",
    "train_df['ForceIndex']=DJ_ForceIndex['ForceIndex']\n",
    "\n",
    "print(DJ_ForceIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuevas features para entrenar el modelo aplicadas a los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aux=test_df.copy()\n",
    "Aux['h_o'] = (Aux['High'] - Aux['Close'])/Aux['Close'] *100 #porcentaje máximo de ganancia en el día respecto al cierre\n",
    "Aux['pct_chng'] = (Aux['Close'] - Aux['Open'])/Aux['Open'] *100 #porcentaje de variación diaria \n",
    "test_df = Aux[['High','Low','Open','Volume','Adj Close','h_o','pct_chng']]\n",
    "#df = A[['Close','pct_chng']]\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo el Commodity Channel Index(CCI) para DJ basándome en la Moving average de 36 días\n",
    "n = 36\n",
    "DJ_CCI_TEST = CCI(test_df, n)\n",
    "CCI_TEST = DJ_CCI_TEST['CCI']\n",
    "test_df['CCI']= CCI_TEST\n",
    "\n",
    "# Calculo Ease of Movement for DJ en 36 días\n",
    "n = 36\n",
    "DJ_EVM = EVM(test_df, n)\n",
    "EVM = DJ_EVM['EVM']\n",
    "test_df['EVM']=EVM\n",
    "\n",
    "\n",
    "# calculo 50 días SMA para DJ\n",
    "n = 50\n",
    "SMA_DJ = SMA(test_df,n)\n",
    "SMA_DJ = SMA_DJ.dropna()\n",
    "SMA = SMA_DJ['SMA']\n",
    "test_df['SMA']=SMA\n",
    "\n",
    "\n",
    "# calculo 200 días SMA para DJ\n",
    "ew = 200\n",
    "EWMA_DJ = EWMA(test_df,ew)\n",
    "EWMA_DJ = EWMA_DJ.dropna()\n",
    "EWMA = EWMA_DJ['EWMA_200']\n",
    "test_df['EWMA']=EWMA\n",
    "\n",
    "# Selecciono un periodo de 36\n",
    "n = 36\n",
    "DJ_ROC = ROC(test_df,n)\n",
    "ROC = DJ_ROC['Rate of Change']\n",
    "test_df['ROC']=ROC\n",
    "\n",
    "# Calculo Bollinger Bands para DJ utilizando Moving average de 36 días\n",
    "n = 36\n",
    "DJ_BBANDS = BBANDS(test_df, n)\n",
    "test_df['UpperBB']=DJ_BBANDS['UpperBB']\n",
    "test_df['LowerBB']=DJ_BBANDS['LowerBB']\n",
    "\n",
    "# Calculo el Force Index para DJ\n",
    "n = 36\n",
    "DJ_ForceIndex = ForceIndex(test_df,n)\n",
    "test_df['ForceIndex']=DJ_ForceIndex['ForceIndex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando los datos:\n",
    "*  Dado que estoy haciendo una predicción de series de tiempo, es necesario que los datos sean secuenciales. Clasifico los datos de entrenamiento y test por fecha. \n",
    "* Posteriormente reinicio el índice lo marco como el índice del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizo los datos de entrenamiento:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.plot(train_df[\"Adj Close\"])\n",
    "plt.xlabel('Date',fontsize=15)\n",
    "plt.ylabel('Adjusted Close Price',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rolling mean\n",
    "close_p = train_df['Adj Close']\n",
    "mavg = close_p.rolling(window=100).mean()\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "close_p.plot(label='DOW JONES')\n",
    "mavg.plot(label='mavg')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling mean: \n",
    "* Obtengo los precios de cierre ajustados de nuestro dataframe y trazo una media móvil (Rolling mean)en nuestros datos.\n",
    "* Rolling mean también es conocida como moving average o media móvil. El promedio móvil nos ayuda a suavizar los datos que tienen muchas fluctuaciones y nos ayuda a ver mejor la tendencia a largo plazo de los datos.\n",
    "* Con el promedio móvil es posible definir un período de tiempo sobre el que tomar el promedio de lo que se conoce como nuestra ventana. En este caso la ventana definida es de 100. Defino 100 porque quiero ver el promedio móvil a largo plazo en los datos.\n",
    "\n",
    "#### Las matemáticas: \n",
    "* El funcionamiento del promedio móvil es el siguiente, se suman los precios de 100 días seguidos y se dividen por 100 para obtener la media. Luego movemos nuestra ventana a la derecha por una. Así que bajamos el primer precio y agregamos un nuevo precio al final.\n",
    "* Otra forma de imaginarlo es pensarlo como un conjunto de 100 precios. Sumamos todos los elementos y dividimos por 100 para obtener nuestro promedio. Luego eliminamos el elemento en `` `a [0]` `` y agregamos otro precio al final de la matriz. Luego sumamos todos los elementos nuevamente y luego dividimos por 100 para obtener nuestro próximo punto promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclusión feature sentimiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Trump_Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=pd.concat([train_df,test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_data.index.name = 'index'\n",
    "#total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['Dates']=total_data.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Cambio las fechas a ints para el entrenamiento del modelo\n",
    "dates_df = total_data.copy()\n",
    "dates_df = dates_df.reset_index()\n",
    "\n",
    "# Almaceno las fechas originales para posteriormente pintar las predicciones.\n",
    "ini_dates = dates_df['Date']\n",
    "dates_df['DateAux'] = dates_df['Date']\n",
    "# Conviento a ints\n",
    "dates_df['Date'] = dates_df['Date'].map(mdates.date2num)\n",
    "\n",
    "dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data=dates_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data['Dates'] = total_data['Dates'].apply(lambda x: str(x))\n",
    "total_data.info()\n",
    "total_data['Dates'] = pd.to_datetime(total_data['Dates'], errors='coerce')\n",
    "\n",
    "total_data['Dates']=total_data['Dates'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_SA=total_data.set_index('Dates').join(df_Trump_Initial.set_index('Date'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_SA=total_data_SA.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_SA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_SA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final = total_data_SA.copy()\n",
    "total_data_final.reset_index(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final = total_data_final.dropna(axis=0, subset=['sentimiento'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final=total_data_final.drop_duplicates(['Date'], keep='last')\n",
    "\n",
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "añado las fechas iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(total_data_final['mensaje'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=total_data_final.query(\"DateAux >= '2014-12-31' and DateAux <='2019-12-31'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=total_data_final.query(\"DateAux >= '2020-01-1' and DateAux <='2020-7-24'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(total_data_final['DateAux'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convirtienfo las fechas: \n",
    "* Creo una copia del dataframe y lo llamo date_df. Almaceno las fechas originales en ini_dates. Posteriomente utilizaré ini_dates para trazar las predicciones y fechas.\n",
    "* A continuación transformo las fechas date_df a números enteros usando mdates.date2num. Es necesario transformar las fechas a números enteros para poder entrenar la red neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraigo los datos de entrenamiento de Adj Close\n",
    "train_data = train_df.loc[:,'Adj Close'].to_numpy()\n",
    "print(train_data.shape) # 1258 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizo los datos antes de alimentar la red LSTM:\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_data = train_data.reshape(-1,1)\n",
    "\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando: \n",
    "* Aquí creo los datos de entrenamiento y los normalizo. Utilizo sklearn para crear un objeto MinMaxScaler ().\n",
    "* MinMaxScaler funciona reduciendo el rango de los valores a un valor entre 0 y 1\n",
    "* A continuación se presento la ecuación para el escalador min-max:\n",
    "<img src=\"Images/MinMax.png\">\n",
    "* Esta es la ecuación que sklearn está haciendo en segundo plano para convertir nuestros datos en el rango deseado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Función que crea un dataset para ser alimentado en una red LSTM'''\n",
    "def crear_LSTM_dataset(dataset, rango):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-rango):\n",
    "        a = dataset[i:(i + rango), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + rango, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero los datos de entrenamiento para el entrenamiento del modelo:\n",
    "time_steps = 36\n",
    "X_train, y_train = crear_LSTM_dataset(train_data, time_steps)\n",
    "\n",
    "# Lo redimensiono [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 36, 1))\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizo los datos: \n",
    "print('X_train:')\n",
    "print(str(scaler.inverse_transform(X_train[0])))\n",
    "print(\"\\n\")\n",
    "print('y_train: ' + str(scaler.inverse_transform(y_train[0].reshape(-1,1)))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando los datos para la red neuronal: \n",
    "* Aquí he creado la función 'crear_LSTM_dataset'. Esta función realiza un bucle desde (0 hasta la longitud de nuestro conjunto de datos: el número de time steps). \n",
    "* Cada índice en la matriz X_train contiene una matriz de 36 días de precios de cierre y la matriz y_train contiene el precio de cierre un día después de nuestros time steps.\n",
    "* Es decir se alimenta la red neuronal con los precios de cierre de los 36 días previos y la red debe ser capaz de realizar la predicción del precio de cierre de las acciones del día inmediatamente posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construyo el modelo \n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(LSTM(units = 100, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units = 100))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Capa de salida\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "# Compilando el modelo\n",
    "model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Ajustando el modelo al conjunto de entrenamiento\n",
    "history = model.fit(X_train, y_train, epochs = 20, batch_size = 10, validation_split=.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial de redes recurrentes y LSTM: \n",
    "* LSTM significa Memoria a corto y largo plazo. Las LSTM son una versión avanzada de las redes neuronales recurrentes. Las redes neuronales recurrentes (RNN) son un tipo especial de red neuronal. Las RNN toman la salida anterior como entrada. En los RNN, la salida anterior influye en la siguiente salida. A continuación se muestra una imagen útil de cómo se vería una RNN de este increíble [artículo](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) escrito por Christopher Olah: \n",
    "\n",
    "<img src=\"Images/RNN-unrolled.png\" width = 600 height = 400>\n",
    "\n",
    "* \"Una red neuronal recurrente puede considerarse como múltiples copias de una misma red, y cada una pasa un mensaje a su sucesora\". -Chris Olah\n",
    "* Las redes neuronales recurrentes sufren el problema de fuga del gradiente. Durante la retropropagación (el proceso recursivo de actualizar los pesos en una red neuronal) se actualizan los pesos de cada capa. Sin embargo, con las redes RNN y la fuga del gradiente, el gradiente se vuelve tan pequeño que continúa actualizando cada capa. A medida que la propagación hacia atrás se propaga a través de las capas, para cuando llega a la primera capa, el valor del gradiente es un valor tan pequeño que hace cambios casi imperceptibles en los pesos. Dado que se realizan cambios mínimos, estas capas iniciales no están aprendiendo o cambiando.\n",
    "* En otras palabras, con secuencias de datos más largas, las RNN olvidan lo que han visto en las capas anteriores y no aprenden correctamente debido al problema de fuga del gradiente. Por ejemplo, si tuviera varios párrafos de texto e intentara predecir la siguiente palabra en una oración, las RNN no recordarían palabras de párrafos anteriores que el modelo ya haya visto. Aquí es donde los LSTM son útiles.\n",
    "\n",
    "## LSTM: \n",
    "Las LSTM son un tipo de RNN con puertas dentro de cada celda LSTM. Estas puertas dentro de las celdas LSTM ayudan a la red a decidir qué datos son importantes para recordar y qué datos pueden olvidarse incluso en series largas de datos.\n",
    "Los tipos de puertas existentes son, la puerta de olvidar o forget gate, la puerta de entrada y la puerta de salida. A continuación se muestra una visualización de cómo se ven estas células LSTM a partir de esto\n",
    "\n",
    "[video](https://www.youtube.com/watch?v=8HyCNIVRbSU). Esta explicación está inspirada en este video y en este artículo [article](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) gracias a lasfantásticas explicaciones existentes en el mismo\n",
    "\n",
    "<img src=\"Images/Gates.png\" width=400 height=400>\n",
    "Por lo tanto, las redes LSTM son secuenciales al igual que las RNN. La salida de la celda anterior se pasa como entrada a la celda siguiente. A continuación se analiza lo que ocurre en el interior de cada puerta perteneciente a una celda LSTM:\n",
    "\n",
    "Las puertas contienen funciones de activación sigmoideas. La función de activación sigmoidea puede considerarse como una función de \"aplastamiento\". Toma datos numéricos y divide los números en un rango de 0 a 1. Esto es importante ya que nos permite evitar que los números en nuestra red se vuelvan masivos y causen errores en el aprendizaje.\n",
    "\n",
    "### Forget gate: \n",
    "La forget gate toma el estado oculto anterior de la celda LSTM anterior y la entrada actual y los multiplica. Los valores más cercanos a 0 significan olvidar los datos, y los valores más cercanos a 1 significa mantener estos datos. \n",
    "\n",
    "* **Las matemáticas:** \n",
    "<img src=\"Images/f.png\" width = 600 height = 600>\n",
    "* La forget gate es la matriz de peso de la forget gate multiplicada por el estado oculto anterior y luego el estado de entrada + algunos sesgos, todos pasados a una función de activación sigmoidea. Después de calcular esto, se pasa al estado de la celda. \n",
    "\n",
    "### Input gate: \n",
    "Esta puerta actualiza el estado de la celda con los nuevos datos que queremos almacenar en el estado de la celda. La puerta de entrada toma el estado oculto anterior multiplicado por la entrada y lo pasa a través de un sigmoide. Los valores más cercanos a 0 no son importantes y los valores más cercanos a 1 son importantes. Luego, el estado oculto anterior se multiplica por la entrada y se pasa a una función de activación que divide los valores en un rango de -1 a 1. Luego, la salida sigmoidea se multiplica por la salida de la función de activación anterior. La salida sigmoide decide qué información es importante mantener de la salida de la función de activación.\n",
    "\n",
    "\n",
    "\n",
    "* **Las matemáticas:**\n",
    "<img src=\"Images/Input_g.png\" width = 600 height = 600>\n",
    "\n",
    "### Cell State: \n",
    "Memoria de la red. Esto puede considerarse como una \"autopista de la información\" que transporta los recuerdos de las celdas anteriores a las celdas futuras. Las puertas realizan cambios en el estado de la celda y luego pasan esa información a la siguiente celda. Una vez que se han calculado la puerta de olvidar y la puerta de entrada, podemos calcular el valor del estado de la celda.\n",
    "\n",
    "\n",
    "\n",
    "* **Las matemáticas:**\n",
    "<img src=\"Images/cell_st.png\" width = 600 height = 600>\n",
    "* El estado de la celda es la salida de la forget gate * estado de la celda anterior + la salida de la puerta de entrada * los valores del estado de la celda pasados ​​desde la celda anterior. Esto es para eliminar ciertos valores que están más cerca de cero que queremos olvidar. Luego se agregan los valores de la puerta de entrada a nuestro valor de estado de celda que queremos pasar a la siguiente celda.  \n",
    "\n",
    "#### Output gate: \n",
    "La puerta de salida decide cuál debería ser el siguiente estado oculto. Tomamos el estado oculto anterior, lo multiplicamos por la entrada y pasamos a una función de activación sigmoidea. Luego pasamos el valor del estado de la celda a una función de activación. Se Multiplica la salida de la función de activación por la salida sigmoidea para decidir qué datos debe llevar el estado oculto a la siguiente celda LSTM.\n",
    "\n",
    "\n",
    "\n",
    "* **Las matemáticas:**\n",
    "<img src=\"Images/output_g.png\" width = 600 height = 600>\n",
    "\n",
    "### Dropout:\n",
    "* Es una técnica de regularización utilizada en el aprendizaje profundo y las redes neuronales.\n",
    "* La regularización es una técnica utilizada para ayudar a las redes a no sobreajustar nuestros datos.\n",
    "* El sobreajuste se produce cuando nuestra red neuronal funciona bien en nuestros datos de entrenamiento pero muy mal en nuestros datos de prueba. Esto significa que la red no generaliza bien, lo que significa que clasifica nuevas imágenes que no ha visto antes de forma incorrecta / deficiente\n",
    "* Básicamente se desactivan algunas neuronas en una capa para que no aprendan ninguna información durante las actualizaciones (retropropagación) de los pesos de la red. Esto permite que otras neuronas activas aprendan mejor y reduzcan el error.\n",
    "### El código: \n",
    "* Secuencial: aquí Construyo la red neuronal. Creo el modelo como secuencial. Secuencial significa que puede crear un modelo capa por capa. Secuencial significa que hay una sola entrada y una única salida, casi como una tubería.\n",
    "* Capas LSTM: Defino dos capas LSTM con un dropout del 20% después de cada capa.\n",
    "* La primera capa defino return_sequences = true. Hago esto porque he apilado capas LSTM y quiero que la segunda capa LSTM tenga una entrada de secuencia tridimensional.\n",
    "* También defino input_shape que lo he configurado como el x.shape para asegurarme de que tenga la misma forma 3D de los datos.\n",
    "* Capa de salida: Un nodo que retorna un número entre 0 y 1.\n",
    "* Compilación: Compilo el modelo. Utilizo el optimizador Adam, que es un tipo de algoritmo de optimización de descenso de gradiente y defino la función de pérdida como el error cuadrático medio. Utilizo Adam para minimizar la función de coste del error cuadrático medio.\n",
    "* Ajuste del modelo: por último, ajusto el modelo utilizando la retropropagación y nuestro optimizador Adam. Defino 20 épocas y un tamaño de lote de 10. También utilizamos la función de división Keras incorporada para dividir nuestros datos en un 70% de entrenamiento y un 30% de prueba.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de los valores de  training & validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dibujando la loss: \n",
    "* Aquí utilizo el código de [keras api](https://keras.io/visualization/)para trazar la pérdida del modelo. A medida que se alcanza a la vigésima época, la pérdida de la prueba y la pérdida del tren están muy cerca y se minimizan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtengo los precios de cierre para 2020 para hacer la predicción\n",
    "test_data = test_df['Adj Close'].values\n",
    "test_data = test_data.reshape(-1,1)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Creo lso datos de test del modelo:\n",
    "time_steps = 36\n",
    "X_test, y_test = crear_LSTM_dataset(test_data_scaled, time_steps)\n",
    "\n",
    "# Almaceno los valores originales\n",
    "y_test = y_test.reshape(-1,1)\n",
    "org_y = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Los redimensiono [samples, time steps, features]\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 36, 1))\n",
    "\n",
    "# Realizo la predicción de los precios con el modelo\n",
    "predicted_y = model.predict(X_test)\n",
    "predicted_y_transform = scaler.inverse_transform(predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_transform[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(org_y, color = 'red', label = 'Real DOWJONES Stock Price')\n",
    "plt.plot(predicted_y_transform, color = 'blue', label = 'Predicted DOWJONES Stock Price')\n",
    "plt.title('DOWJONES Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('DOWJONES Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando la predicción: \n",
    "* Aquí tenemos nuestra red neuronal para hacer predicciones sobre los datos de stock de del índice Dow Jones no vistos por la red en el año 2020.\n",
    "* Primero obtengo los datos de precios de cierre de acciones de 2020 del dataframe de prueba y los transformo en valores entre 0 y 1.\n",
    "* Utilizo mi función crear_LSTM_dataset nuevamente para convertir los datos de test en lotes de 36 precios de acciones. \n",
    "* Almaceno los valores y originales en una variable org_y. \n",
    "* Por último, La red realiza las predicciones de precios.\n",
    "* Como puede observarse en el gráfico de predicción anterior, el modelo funcionó bastante bien y siguió el comportamiento durante todo el año de datos no vistos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the error with MSE\n",
    "real_mse = np.mean(np.square(org_y - predicted_y_transform))\n",
    "scaled_mse = real_mse / (np.max(org_y) - np.min(org_y)) * 100\n",
    "\n",
    "print('scaled_mse = ' + str(scaled_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_org_y = org_y.mean()\n",
    "mean_predicted_y = predicted_y_transform.mean()\n",
    "print(mean_org_y,mean_predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (mean_org_y / mean_predicted_y)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (org_y / predicted_y_transform)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predicted_y)):\n",
    "    print('iteration=%d, Predicted=%f, Expected=%f' % (i+1,   predicted_y_transform[i], org_y[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=total_data_final['sentimiento'].values\n",
    "type(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = total_data_final['Date'].map(mdates.num2date)\n",
    "aux"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
